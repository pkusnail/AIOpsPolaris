"""
æ›´æ–°çŸ¥è¯†å›¾è°±ï¼Œæ„å»ºå®Œæ•´çš„å®éªŒç¯å¢ƒæ‹“æ‰‘
åŸºäºsystem_architecture.mdæ„å»ºçœŸå®çš„å¾®æœåŠ¡æ¶æ„
"""

import asyncio
import logging
from neo4j import GraphDatabase
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExperimentTopologyBuilder:
    """å®éªŒç¯å¢ƒæ‹“æ‰‘æ„å»ºå™¨"""
    
    def __init__(self):
        self.driver = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "aiops123")
        )
    
    async def build_complete_topology(self):
        """æ„å»ºå®Œæ•´çš„å®éªŒæ‹“æ‰‘"""
        logger.info("å¼€å§‹æ„å»ºå®Œæ•´çš„å®éªŒæ‹“æ‰‘...")
        
        with self.driver.session() as session:
            # 1. æ¸…ç†æ—§æ•°æ®
            await self._clean_old_topology(session)
            
            # 2. åˆ›å»ºæœåŠ¡èŠ‚ç‚¹
            await self._create_services(session)
            
            # 3. åˆ›å»ºä¸»æœºå’Œæ•°æ®ä¸­å¿ƒèŠ‚ç‚¹
            await self._create_infrastructure(session)
            
            # 4. åˆ›å»ºæ•°æ®åº“èŠ‚ç‚¹
            await self._create_databases(session)
            
            # 5. å»ºç«‹æœåŠ¡ä¾èµ–å…³ç³»
            await self._create_dependencies(session)
            
            # 6. å»ºç«‹éƒ¨ç½²å…³ç³»
            await self._create_deployments(session)
            
            # 7. å»ºç«‹é—®é¢˜å’Œæ•…éšœèŠ‚ç‚¹
            await self._create_issues(session)
            
            # 8. åˆ›å»ºè°ƒç”¨é“¾è·¯
            await self._create_call_paths(session)
            
        logger.info("å®Œæ•´æ‹“æ‰‘æ„å»ºå®Œæˆ")
    
    async def _clean_old_topology(self, session):
        """æ¸…ç†æ—§çš„æ‹“æ‰‘æ•°æ®"""
        logger.info("æ¸…ç†æ—§çš„æ‹“æ‰‘æ•°æ®...")
        
        # åˆ é™¤å®éªŒç›¸å…³çš„èŠ‚ç‚¹å’Œå…³ç³»ï¼Œä¿ç•™æ–‡æ¡£
        cleanup_queries = [
            "MATCH (n:TestNode) DETACH DELETE n",
            "MATCH (n:Service) DETACH DELETE n", 
            "MATCH (n:Host) DETACH DELETE n",
            "MATCH (n:DataCenter) DETACH DELETE n",
            "MATCH (n:Database) DETACH DELETE n",
            "MATCH (n:Issue) DETACH DELETE n",
            "MATCH (n:CallPath) DETACH DELETE n"
        ]
        
        for query in cleanup_queries:
            session.run(query)
    
    async def _create_services(self, session):
        """åˆ›å»ºæœåŠ¡èŠ‚ç‚¹"""
        logger.info("åˆ›å»ºæœåŠ¡èŠ‚ç‚¹...")
        
        services = [
            {
                "name": "service-a",
                "type": "api-gateway", 
                "technology": "Spring Boot",
                "port": 8080,
                "dc": "DC-East",
                "description": "API Gateway - ç³»ç»Ÿå…¥å£ç‚¹ï¼Œè´Ÿè´£è¯·æ±‚è·¯ç”±å’Œè´Ÿè½½å‡è¡¡"
            },
            {
                "name": "service-b", 
                "type": "business-logic",
                "technology": "Spring Boot",
                "port": 8081,
                "dc": "DC-East",
                "description": "Primary Business Logic - ä¸»è¦ä¸šåŠ¡é€»è¾‘å¤„ç†"
            },
            {
                "name": "service-c",
                "type": "business-logic", 
                "technology": "Node.js",
                "port": 8082,
                "dc": "DC-East",
                "description": "Secondary Business Logic - å¤‡é€‰ä¸šåŠ¡é€»è¾‘å¤„ç†"
            },
            {
                "name": "service-d1",
                "type": "data-processing",
                "technology": "Java MyBatis", 
                "port": 8083,
                "dc": "DC-East",
                "description": "Data Processing Instance 1"
            },
            {
                "name": "service-d2",
                "type": "data-processing",
                "technology": "Java MyBatis",
                "port": 8083,
                "dc": "DC-East", 
                "description": "Data Processing Instance 2"
            },
            {
                "name": "service-d3",
                "type": "data-processing",
                "technology": "Java MyBatis",
                "port": 8083,
                "dc": "DC-East",
                "description": "Data Processing Instance 3"
            },
            {
                "name": "service-f",
                "type": "external-integration",
                "technology": "Python Flask",
                "port": 8085,
                "dc": "DC-West",
                "description": "External Integration - å¤–éƒ¨APIé›†æˆå’Œæ”¯ä»˜å¤„ç†"
            }
        ]
        
        for service in services:
            session.run(
                """
                CREATE (s:Service {
                    name: $name,
                    type: $type,
                    technology: $technology,
                    port: $port,
                    datacenter: $dc,
                    description: $description,
                    status: 'active',
                    created_at: datetime()
                })
                """,
                **service
            )
            logger.info(f"åˆ›å»ºæœåŠ¡: {service['name']}")
    
    async def _create_infrastructure(self, session):
        """åˆ›å»ºåŸºç¡€è®¾æ–½èŠ‚ç‚¹"""
        logger.info("åˆ›å»ºåŸºç¡€è®¾æ–½èŠ‚ç‚¹...")
        
        # æ•°æ®ä¸­å¿ƒ
        datacenters = [
            {
                "name": "DC-East",
                "location": "ä¸œéƒ¨æ•°æ®ä¸­å¿ƒ", 
                "subnet": "10.1.0.0/16",
                "description": "ä¸»è¦æ•°æ®ä¸­å¿ƒ"
            },
            {
                "name": "DC-West",
                "location": "è¥¿éƒ¨æ•°æ®ä¸­å¿ƒ",
                "subnet": "10.2.0.0/16", 
                "description": "å¤‡ç”¨æ•°æ®ä¸­å¿ƒ"
            }
        ]
        
        for dc in datacenters:
            session.run(
                """
                CREATE (dc:DataCenter {
                    name: $name,
                    location: $location,
                    subnet: $subnet,
                    description: $description,
                    created_at: datetime()
                })
                """,
                **dc
            )
        
        # ä¸»æœºèŠ‚ç‚¹
        hosts = [
            {
                "name": "host-east-1",
                "ip": "10.1.1.10",
                "datacenter": "DC-East",
                "cpu_cores": 8,
                "memory_gb": 16,
                "description": "ä¸œéƒ¨ä¸»æœº1"
            },
            {
                "name": "host-east-2", 
                "ip": "10.1.1.11",
                "datacenter": "DC-East",
                "cpu_cores": 8,
                "memory_gb": 16,
                "description": "ä¸œéƒ¨ä¸»æœº2"
            },
            {
                "name": "host-east-3",
                "ip": "10.1.1.12", 
                "datacenter": "DC-East",
                "cpu_cores": 16,
                "memory_gb": 32,
                "description": "ä¸œéƒ¨æ•°æ®åº“ä¸»æœº"
            },
            {
                "name": "host-west-1",
                "ip": "10.2.1.10",
                "datacenter": "DC-West", 
                "cpu_cores": 4,
                "memory_gb": 8,
                "description": "è¥¿éƒ¨ä¸»æœº1"
            }
        ]
        
        for host in hosts:
            session.run(
                """
                CREATE (h:Host {
                    name: $name,
                    ip: $ip,
                    datacenter: $datacenter,
                    cpu_cores: $cpu_cores,
                    memory_gb: $memory_gb,
                    description: $description,
                    status: 'online',
                    created_at: datetime()
                })
                """,
                **host
            )
            logger.info(f"åˆ›å»ºä¸»æœº: {host['name']}")
    
    async def _create_databases(self, session):
        """åˆ›å»ºæ•°æ®åº“èŠ‚ç‚¹"""
        logger.info("åˆ›å»ºæ•°æ®åº“èŠ‚ç‚¹...")
        
        databases = [
            {
                "name": "mysql-primary",
                "type": "MySQL",
                "version": "8.0",
                "port": 3306,
                "datacenter": "DC-East",
                "connection_pool": 20,
                "description": "MySQLä¸»æ•°æ®åº“"
            },
            {
                "name": "postgresql-secondary", 
                "type": "PostgreSQL",
                "version": "14.0",
                "port": 5432,
                "datacenter": "DC-West",
                "connection_pool": 15,
                "description": "PostgreSQLè¾…åŠ©æ•°æ®åº“"
            }
        ]
        
        for db in databases:
            session.run(
                """
                CREATE (db:Database {
                    name: $name,
                    type: $type,
                    version: $version,
                    port: $port,
                    datacenter: $datacenter,
                    connection_pool: $connection_pool,
                    description: $description,
                    status: 'online',
                    created_at: datetime()
                })
                """,
                **db
            )
    
    async def _create_dependencies(self, session):
        """åˆ›å»ºæœåŠ¡ä¾èµ–å…³ç³»"""
        logger.info("åˆ›å»ºæœåŠ¡ä¾èµ–å…³ç³»...")
        
        dependencies = [
            # API Gatewayçš„ä¾èµ–
            ("service-a", "service-b", "ROUTES_TO", {"weight": 0.6, "timeout": "5s"}),
            ("service-a", "service-c", "ROUTES_TO", {"weight": 0.4, "timeout": "8s"}),
            
            # Business Logicçš„ä¾èµ–
            ("service-b", "service-d1", "CALLS", {"load_balance": True}),
            ("service-b", "service-d2", "CALLS", {"load_balance": True}),
            ("service-b", "service-d3", "CALLS", {"load_balance": True}),
            ("service-c", "service-f", "CALLS", {"cross_dc": True, "timeout": "10s"}),
            
            # Data Processingçš„æ•°æ®åº“ä¾èµ–
            ("service-d1", "mysql-primary", "CONNECTS_TO", {"pool_size": 5}),
            ("service-d2", "mysql-primary", "CONNECTS_TO", {"pool_size": 5}),
            ("service-d3", "mysql-primary", "CONNECTS_TO", {"pool_size": 5}),
            
            # External Integrationçš„æ•°æ®åº“ä¾èµ–
            ("service-f", "postgresql-secondary", "CONNECTS_TO", {"pool_size": 8}),
        ]
        
        for from_node, to_node, rel_type, properties in dependencies:
            session.run(
                f"""
                MATCH (from {{name: $from_node}})
                MATCH (to {{name: $to_node}})
                CREATE (from)-[r:{rel_type} $properties]->(to)
                """,
                from_node=from_node,
                to_node=to_node,
                properties=properties
            )
            logger.info(f"åˆ›å»ºä¾èµ–: {from_node} --{rel_type}--> {to_node}")
    
    async def _create_deployments(self, session):
        """åˆ›å»ºéƒ¨ç½²å…³ç³»"""
        logger.info("åˆ›å»ºéƒ¨ç½²å…³ç³»...")
        
        deployments = [
            ("service-a", "host-east-1"),
            ("service-b", "host-east-1"), 
            ("service-c", "host-east-2"),
            ("service-d1", "host-east-2"),
            ("service-d2", "host-east-2"),
            ("service-d3", "host-east-2"),
            ("mysql-primary", "host-east-3"),
            ("service-f", "host-west-1"),
            ("postgresql-secondary", "host-west-1")
        ]
        
        for service, host in deployments:
            session.run(
                """
                MATCH (s {name: $service})
                MATCH (h:Host {name: $host})
                CREATE (s)-[:DEPLOYED_ON]->(h)
                """,
                service=service,
                host=host
            )
            logger.info(f"åˆ›å»ºéƒ¨ç½²å…³ç³»: {service} --> {host}")
    
    async def _create_issues(self, session):
        """åˆ›å»ºé—®é¢˜å’Œæ•…éšœèŠ‚ç‚¹"""
        logger.info("åˆ›å»ºé—®é¢˜å’Œæ•…éšœèŠ‚ç‚¹...")
        
        issues = [
            {
                "name": "Service-B CPUè¿‡è½½",
                "type": "performance",
                "severity": "high",
                "category": "CPU",
                "description": "Service-Bå¤„ç†å¤æ‚ä¸šåŠ¡é€»è¾‘å¯¼è‡´CPUè¿‡è½½"
            },
            {
                "name": "Service-D1å†…å­˜æ³„æ¼",
                "type": "memory", 
                "severity": "medium",
                "category": "Memory",
                "description": "Service-D1å­˜åœ¨å†…å­˜æ³„æ¼é—®é¢˜"
            },
            {
                "name": "MySQLè¿æ¥æ± è€—å°½",
                "type": "database",
                "severity": "high", 
                "category": "Database",
                "description": "MySQLè¿æ¥æ± è¢«è€—å°½ï¼Œæ–°è¿æ¥è¢«æ‹’ç»"
            },
            {
                "name": "è·¨DCç½‘ç»œåˆ†åŒº",
                "type": "network",
                "severity": "critical",
                "category": "Network", 
                "description": "DC-Eaståˆ°DC-Westç½‘ç»œä¸­æ–­"
            },
            {
                "name": "Service-Få¤–éƒ¨APIè¶…æ—¶",
                "type": "external",
                "severity": "medium",
                "category": "Integration",
                "description": "Payment Gateway APIå“åº”è¶…æ—¶"
            }
        ]
        
        for issue in issues:
            session.run(
                """
                CREATE (i:Issue {
                    name: $name,
                    type: $type,
                    severity: $severity,
                    category: $category,
                    description: $description,
                    status: 'active',
                    created_at: datetime()
                })
                """,
                **issue
            )
        
        # åˆ›å»ºé—®é¢˜å½±å“å…³ç³»
        issue_impacts = [
            ("Service-B CPUè¿‡è½½", "service-b"),
            ("Service-D1å†…å­˜æ³„æ¼", "service-d1"),
            ("MySQLè¿æ¥æ± è€—å°½", "mysql-primary"),
            ("è·¨DCç½‘ç»œåˆ†åŒº", "service-f"),
            ("Service-Få¤–éƒ¨APIè¶…æ—¶", "service-f")
        ]
        
        for issue, affected_service in issue_impacts:
            session.run(
                """
                MATCH (i:Issue {name: $issue})
                MATCH (s {name: $affected_service})
                CREATE (i)-[:AFFECTS]->(s)
                """,
                issue=issue,
                affected_service=affected_service
            )
    
    async def _create_call_paths(self, session):
        """åˆ›å»ºè°ƒç”¨é“¾è·¯"""
        logger.info("åˆ›å»ºè°ƒç”¨é“¾è·¯...")
        
        # ä¸»è°ƒç”¨è·¯å¾„
        call_paths = [
            {
                "name": "Path-A-B-D",
                "description": "ç”¨æˆ·è¯·æ±‚ -> A -> B -> D -> MySQL",
                "traffic_percent": 60,
                "expected_latency": "< 500ms"
            },
            {
                "name": "Path-A-C-F", 
                "description": "ç”¨æˆ·è¯·æ±‚ -> A -> C -> F -> External API",
                "traffic_percent": 40,
                "expected_latency": "< 800ms"
            }
        ]
        
        for path in call_paths:
            session.run(
                """
                CREATE (p:CallPath {
                    name: $name,
                    description: $description, 
                    traffic_percent: $traffic_percent,
                    expected_latency: $expected_latency,
                    created_at: datetime()
                })
                """,
                **path
            )
    
    async def verify_topology(self):
        """éªŒè¯æ‹“æ‰‘å®Œæ•´æ€§"""
        logger.info("éªŒè¯æ‹“æ‰‘å®Œæ•´æ€§...")
        
        with self.driver.session() as session:
            # ç»Ÿè®¡èŠ‚ç‚¹
            counts = {}
            node_types = ["Service", "Host", "Database", "DataCenter", "Issue", "CallPath"]
            
            for node_type in node_types:
                result = session.run(f"MATCH (n:{node_type}) RETURN count(n) as count")
                counts[node_type] = result.single()["count"]
            
            # ç»Ÿè®¡å…³ç³»
            rel_result = session.run("MATCH ()-[r]->() RETURN count(r) as count")
            rel_count = rel_result.single()["count"]
            
            logger.info("=== æ‹“æ‰‘éªŒè¯ç»“æœ ===")
            for node_type, count in counts.items():
                logger.info(f"{node_type}: {count} ä¸ªèŠ‚ç‚¹")
            logger.info(f"å…³ç³»æ€»æ•°: {rel_count} ä¸ª")
            
            # éªŒè¯å…³é”®è·¯å¾„
            critical_paths = [
                "service-a --> service-b",
                "service-b --> service-d1", 
                "service-c --> service-f"
            ]
            
            for path in critical_paths:
                parts = path.split(" --> ")
                result = session.run(
                    """
                    MATCH (a {name: $from_node})-[r]->(b {name: $to_node})
                    RETURN type(r) as rel_type
                    """,
                    from_node=parts[0],
                    to_node=parts[1]
                )
                
                rel_types = [record["rel_type"] for record in result]
                if rel_types:
                    logger.info(f"âœ… {path}: {', '.join(rel_types)}")
                else:
                    logger.warning(f"âŒ {path}: ç¼ºå°‘å…³ç³»")
    
    def close(self):
        self.driver.close()


async def main():
    """ä¸»å‡½æ•°"""
    builder = ExperimentTopologyBuilder()
    
    try:
        await builder.build_complete_topology()
        await builder.verify_topology()
        print("\nğŸ‰ å®Œæ•´çš„å®éªŒæ‹“æ‰‘æ„å»ºæˆåŠŸï¼")
        print("åŒ…å«çš„ç»„ä»¶:")
        print("- 7ä¸ªå¾®æœåŠ¡ (A, B, C, D1-D3, F)")
        print("- 4ä¸ªä¸»æœºèŠ‚ç‚¹ (DC-East: 3å°, DC-West: 1å°)")
        print("- 2ä¸ªæ•°æ®ä¸­å¿ƒ (DC-East, DC-West)")
        print("- 2ä¸ªæ•°æ®åº“ (MySQL, PostgreSQL)")
        print("- 5ç±»é—®é¢˜åœºæ™¯")
        print("- å®Œæ•´çš„ä¾èµ–å’Œéƒ¨ç½²å…³ç³»")
        
    except Exception as e:
        logger.error(f"æ„å»ºæ‹“æ‰‘å¤±è´¥: {e}")
        raise
    finally:
        builder.close()


if __name__ == "__main__":
    asyncio.run(main())